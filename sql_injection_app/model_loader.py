import os
import logging
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from typing import Tuple

# ==================== ç¯å¢ƒé…ç½® ====================
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"  # ä½¿ç”¨ HuggingFace é•œåƒ

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SQLiDetector")

# ==================== æ¨¡å‹è·¯å¾„è®¾ç½® ====================
MODEL_ID = "cssupport/mobilebert-sql-injection-detect"
MODEL_PATH = "./saved_model/mobilebert_sql"

# ==================== æ¨¡å‹åŠ è½½å‡½æ•° ====================
def load_model_and_tokenizer():
    try:
        if os.path.exists(MODEL_PATH) and os.path.isdir(MODEL_PATH):
            logger.info("ğŸ” æ­£åœ¨ä»æœ¬åœ°åŠ è½½æ¨¡å‹...")
            tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
            model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
        else:
            logger.info(f"ğŸŒ æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä» HuggingFace é•œåƒä¸‹è½½å¹¶ä¿å­˜åˆ°ï¼š{MODEL_PATH}")
            tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
            model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)
            os.makedirs(MODEL_PATH, exist_ok=True)
            tokenizer.save_pretrained(MODEL_PATH)
            model.save_pretrained(MODEL_PATH)

        model = model.to("cpu")
        model.eval()
        logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå·²åˆ‡æ¢è‡³ CPU æ¨¡å¼")
        return tokenizer, model

    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        raise RuntimeError("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ¨¡å‹è·¯å¾„ã€‚")

# âœ… åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…åŠ è½½ä¸€æ¬¡ï¼‰
tokenizer, model = load_model_and_tokenizer()

# ==================== æ£€æµ‹å‡½æ•° ====================
def predict_sql_injection(sql_text: str) -> Tuple[str, float]:
    """
    ä½¿ç”¨ MobileBERT æ¨¡å‹æ£€æµ‹ SQL è¯­å¥æ˜¯å¦å­˜åœ¨æ³¨å…¥æ”»å‡»
    è¿”å›: labelï¼ˆæ­£å¸¸è¯­å¥ / æ³¨å…¥æ”»å‡»ï¼‰, ç½®ä¿¡åº¦ç™¾åˆ†æ¯”
    """
    try:
        if not sql_text or not isinstance(sql_text, str):
            raise ValueError("SQLè¾“å…¥ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")

        inputs = tokenizer(sql_text, return_tensors="pt", truncation=True, padding=True, max_length=256)
        inputs = {k: v.to("cpu") for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=1)

        predicted_class = torch.argmax(probs, dim=1).item()
        confidence = round(probs[0][predicted_class].item() * 100, 2)
        label = "æ³¨å…¥æ”»å‡»" if predicted_class == 1 else "æ­£å¸¸è¯­å¥"

        logger.info(f"æ£€æµ‹å®Œæˆ | ç»“æœ: {label} | ç½®ä¿¡åº¦: {confidence}%")
        return label, confidence

    except Exception as e:
        logger.error(f"âš ï¸ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{e}")
        return "æ£€æµ‹å¤±è´¥", 0.0
